# =============================================================================
# GEngine Echoes of Emergence - Environment Configuration
# =============================================================================
# Copy this file to .env and customize as needed.
# All variables are optional with sensible defaults.
#
# Usage:
#   cp .env.sample .env
#   docker compose up
#
# =============================================================================

# =============================================================================
# Port Mappings (host:container)
# =============================================================================
# Override the default port mappings for host machine access

# Simulation service port (default: 8000)
SIMULATION_PORT=8000

# Gateway service port (default: 8100)
GATEWAY_PORT=8100

# LLM service port (default: 8001)
LLM_PORT=8001

# =============================================================================
# Simulation Service Configuration
# =============================================================================
# These configure the core simulation engine

# World to load at startup (default: default)
# Available worlds are in content/worlds/
ECHOES_SERVICE_WORLD=default

# =============================================================================
# LLM Service Configuration
# =============================================================================
# Configure the LLM provider for natural language processing

# Provider selection: stub, openai, or anthropic
# - stub: Uses keyword matching (no API key required, good for testing)
# - openai: Uses OpenAI API (requires API key and model)
# - anthropic: Uses Anthropic API (requires API key and model)
ECHOES_LLM_PROVIDER=stub

# API key for the selected provider (required for openai/anthropic)
# ECHOES_LLM_API_KEY=your-api-key-here

# Model identifier (required for openai/anthropic)
# Examples:
#   OpenAI: gpt-4-turbo-preview, gpt-4, gpt-3.5-turbo
#   Anthropic: claude-3-5-sonnet-20241022, claude-3-opus-20240229
# ECHOES_LLM_MODEL=gpt-4-turbo-preview

# Sampling temperature (0.0-1.0, default: 0.7)
# Lower = more deterministic, higher = more creative
ECHOES_LLM_TEMPERATURE=0.7

# Maximum tokens in response (default: 1000)
ECHOES_LLM_MAX_TOKENS=1000

# Request timeout in seconds (default: 30)
ECHOES_LLM_TIMEOUT=30

# Number of retries on API errors (default: 2)
ECHOES_LLM_MAX_RETRIES=2

# =============================================================================
# Gateway Service Configuration
# =============================================================================
# These are typically set automatically in docker-compose.yml
# Only override if you need custom networking

# URL to the simulation service (auto-configured in Docker)
# ECHOES_GATEWAY_SERVICE_URL=http://simulation:8000

# URL to the LLM service for natural language commands (auto-configured)
# ECHOES_GATEWAY_LLM_URL=http://llm:8001
